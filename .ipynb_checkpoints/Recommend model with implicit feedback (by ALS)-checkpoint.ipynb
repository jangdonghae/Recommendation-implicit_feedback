{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-8fb00f977ffa>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['user_id'] = data['user'].astype(\"category\").cat.codes\n",
      "<ipython-input-2-8fb00f977ffa>:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['artist_id'] = data['artist'].astype(\"category\").cat.codes\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#-------------------------\n",
    "# LOAD AND PREP THE DATA\n",
    "#-------------------------\n",
    " \n",
    "raw_data = pd.read_table('data/usersha1-artmbid-artname-plays.tsv')\n",
    "raw_data = raw_data.drop(raw_data.columns[1], axis=1)\n",
    "raw_data.columns = ['user', 'artist', 'plays']\n",
    " \n",
    "# Drop rows with missing values\n",
    "data = raw_data.dropna()\n",
    "\n",
    "# Convert artists names into numerical IDs\n",
    "data['user_id'] = data['user'].astype(\"category\").cat.codes\n",
    "data['artist_id'] = data['artist'].astype(\"category\").cat.codes\n",
    "\n",
    "# Create a lookup frame so we can get the artist names back in \n",
    "# readable form later.\n",
    "item_lookup = data[['artist_id', 'artist']].drop_duplicates()\n",
    "item_lookup['artist_id'] = item_lookup.artist_id.astype(str)\n",
    "\n",
    "data = data.drop(['user', 'artist'], axis=1)\n",
    "\n",
    "# Drop any rows that have 0 plays\n",
    "data = data.loc[data.plays != 0]\n",
    "\n",
    "# Create lists of all users, artists and plays\n",
    "users = list(np.sort(data.user_id.unique()))\n",
    "artists = list(np.sort(data.artist_id.unique()))\n",
    "plays = list(data.plays)\n",
    "\n",
    "# Get the rows and columns for our new matrix\n",
    "rows = data.user_id.astype(int)\n",
    "cols = data.artist_id.astype(int)\n",
    "\n",
    "# Contruct a sparse matrix for our users and items containing number of plays\n",
    "data_sparse = sparse.csr_matrix((plays, (rows, cols)), shape=(len(users), len(artists)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plays</th>\n",
       "      <th>user_id</th>\n",
       "      <th>artist_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1099</td>\n",
       "      <td>0</td>\n",
       "      <td>90933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>897</td>\n",
       "      <td>0</td>\n",
       "      <td>185367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>717</td>\n",
       "      <td>0</td>\n",
       "      <td>106704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>155241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>691</td>\n",
       "      <td>0</td>\n",
       "      <td>220128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   plays  user_id  artist_id\n",
       "0   1099        0      90933\n",
       "1    897        0     185367\n",
       "2    717        0     106704\n",
       "3    706        0     155241\n",
       "4    691        0     220128"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\"\"\" \n",
    "Implementation of Alternating Least Squares with implicit data. We iteratively\n",
    "compute the user (x_u) and item (y_i) vectors using the following formulas:\n",
    "\n",
    "x_u = ((Y.T*Y + Y.T*(Cu - I) * Y) + lambda*I)^-1 * (X.T * Cu * p(u))\n",
    "y_i = ((X.T*X + X.T*(Ci - I) * X) + lambda*I)^-1 * (Y.T * Ci * p(i))\n",
    "\n",
    "Args:\n",
    "    sparse_data (csr_matrix): Our sparse user-by-item matrix\n",
    "\n",
    "    alpha_val (int): The rate in which we'll increase our confidence\n",
    "    in a preference with more interactions.\n",
    "\n",
    "    iterations (int): How many times we alternate between fixing and \n",
    "    updating our user and item vectors\n",
    "\n",
    "    lambda_val (float): Regularization value\n",
    "\n",
    "    features (int): How many latent features we want to compute.\n",
    "\n",
    "Returns:     \n",
    "    X (csr_matrix): user vectors of size users-by-features\n",
    "\n",
    "    Y (csr_matrix): item vectors of size items-by-features}\n",
    "\"\"\"\n",
    "def implicit_als(sparse_data, alpha_val=40, iterations=10, lambda_val=0.1, features=10):\n",
    "\n",
    "\n",
    "    # Calculate the foncidence for each value in our data\n",
    "    confidence = sparse_data * alpha_val\n",
    "    \n",
    "    # Get the size of user rows and item columns\n",
    "    user_size, item_size = sparse_data.shape\n",
    "    \n",
    "    # We create the user vectors X of size users-by-features, the item vectors\n",
    "    # Y of size items-by-features and randomly assign the values.\n",
    "    X = sparse.csr_matrix(np.random.normal(size = (user_size, features)))\n",
    "    Y = sparse.csr_matrix(np.random.normal(size = (item_size, features)))\n",
    "    \n",
    "    #Precompute I and lambda * I\n",
    "    X_I = sparse.eye(user_size)\n",
    "    Y_I = sparse.eye(item_size)\n",
    "    \n",
    "    I = sparse.eye(features)\n",
    "    lI = lambda_val * I\n",
    "    \n",
    "    # Start main loop. For each iteration we first compute X and then Y\n",
    "    for i in range(iterations):\n",
    "        print('iteration {} of {}'.format(i+1, iterations))\n",
    "        \n",
    "        # Precompute Y-transpose-Y and X-transpose-X\n",
    "        yTy = Y.T.dot(Y)\n",
    "        xTx = X.T.dot(X)\n",
    "\n",
    "        # Loop through all users\n",
    "        for u in range(user_size):\n",
    "\n",
    "            # Get the user row.\n",
    "            u_row = confidence[u,:].toarray() \n",
    "\n",
    "            # Calculate the binary preference p(u)\n",
    "            p_u = u_row.copy()\n",
    "            p_u[p_u != 0] = 1.0\n",
    "\n",
    "            # Calculate Cu and Cu - I\n",
    "            CuI = sparse.diags(u_row, [0])\n",
    "            Cu = CuI + Y_I\n",
    "\n",
    "            # Put it all together and compute the final formula\n",
    "            yT_CuI_y = Y.T.dot(CuI).dot(Y)\n",
    "            yT_Cu_pu = Y.T.dot(Cu).dot(p_u.T)\n",
    "            X[u] = spsolve(yTy + yT_CuI_y + lI, yT_Cu_pu)\n",
    "\n",
    "    \n",
    "        for i in range(item_size):\n",
    "\n",
    "            # Get the item column and transpose it.\n",
    "            i_row = confidence[:,i].T.toarray()\n",
    "\n",
    "            # Calculate the binary preference p(i)\n",
    "            p_i = i_row.copy()\n",
    "            p_i[p_i != 0] = 1.0\n",
    "\n",
    "            # Calculate Ci and Ci - I\n",
    "            CiI = sparse.diags(i_row, [0])\n",
    "            Ci = CiI + X_I\n",
    "\n",
    "            # Put it all together and compute the final formula\n",
    "            xT_CiI_x = X.T.dot(CiI).dot(X)\n",
    "            xT_Ci_pi = X.T.dot(Ci).dot(p_i.T)\n",
    "            Y[i] = spsolve(xTx + xT_CiI_x + lI, xT_Ci_pi)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_vecs, item_vecs = implicit_als(data_sparse, iterations=20, features=20, alpha_val=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is so slow.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is so slow\n",
    "We need new method.\n",
    "Implementation is based on the code by Ben Frederickson, which used Conjugate Gradient method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonzeros(m, row):\n",
    "    for index in range(m.indptr[row], m.indptr[row+1]):\n",
    "        yield m.indices[index], m.data[index]\n",
    "      \n",
    "      \n",
    "def implicit_als_cg(Cui, features=20, iterations=20, lambda_val=0.1):\n",
    "    user_size, item_size = Cui.shape\n",
    "\n",
    "    X = np.random.rand(user_size, features) * 0.01\n",
    "    Y = np.random.rand(item_size, features) * 0.01\n",
    "\n",
    "    Cui, Ciu = Cui.tocsr(), Cui.T.tocsr()\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "        print('iteration {} of {}'.format(iteration+1, iterations))\n",
    "        least_squares_cg(Cui, X, Y, lambda_val)\n",
    "        least_squares_cg(Ciu, Y, X, lambda_val)\n",
    "    \n",
    "    return sparse.csr_matrix(X), sparse.csr_matrix(Y)\n",
    "  \n",
    "  \n",
    "def least_squares_cg(Cui, X, Y, lambda_val, cg_steps=3):\n",
    "    users, features = X.shape\n",
    "    \n",
    "    YtY = Y.T.dot(Y) + lambda_val * np.eye(features)\n",
    "\n",
    "    for u in range(users):\n",
    "\n",
    "        x = X[u]\n",
    "        r = -YtY.dot(x)\n",
    "\n",
    "        for i, confidence in nonzeros(Cui, u):\n",
    "            r += (confidence - (confidence - 1) * Y[i].dot(x)) * Y[i]\n",
    "\n",
    "        p = r.copy()\n",
    "        rsold = r.dot(r)\n",
    "\n",
    "        for it in range(cg_steps):\n",
    "            Ap = YtY.dot(p)\n",
    "            for i, confidence in nonzeros(Cui, u):\n",
    "                Ap += (confidence - 1) * Y[i].dot(p) * Y[i]\n",
    "\n",
    "            alpha = rsold / p.dot(Ap)\n",
    "            x += alpha * p\n",
    "            r -= alpha * Ap\n",
    "\n",
    "            rsnew = r.dot(r)\n",
    "            p = r + (rsnew / rsold) * p\n",
    "            rsold = rsnew\n",
    "\n",
    "        X[u] = x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1 of 20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-d6d2a12b4425>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0malpha_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mconf_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata_sparse\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0malpha_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'double'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0muser_vecs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_vecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimplicit_als_cg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-06b281c62552>\u001b[0m in \u001b[0;36mimplicit_als_cg\u001b[1;34m(Cui, features, iterations, lambda_val)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'iteration {} of {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mleast_squares_cg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mleast_squares_cg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCiu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-06b281c62552>\u001b[0m in \u001b[0;36mleast_squares_cg\u001b[1;34m(Cui, X, Y, lambda_val, cg_steps)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfidence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnonzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mconfidence\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mconfidence\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "alpha_val = 15\n",
    "conf_data = (data_sparse * alpha_val).astype('double')\n",
    "user_vecs, item_vecs = implicit_als_cg(conf_data, iterations=20, features=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import implicit\n",
    "# Initialize the als model and fit it using the sparse item-user matrix\n",
    "model = implicit.als.AlternatingLeastSquares(factors=20, regularization=0.1, iterations=20)\n",
    "\n",
    "# Calculate the confidence by multiplying it by our alpha value.\n",
    "alpha_val = 15\n",
    "data_conf = (sparse_item_user * alpha_val).astype('double')\n",
    "\n",
    "# Fit the model\n",
    "model.fit(data_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "# FIND SIMILAR ITEMS\n",
    "#------------------------------\n",
    "\n",
    "# Let's find similar artists to Jay-Z. \n",
    "# Note that this ID might be different for you if you're using\n",
    "# the full dataset or if you've sliced it somehow. \n",
    "item_id = 10277\n",
    "\n",
    "# Get the item row for Jay-Z\n",
    "item_vec = item_vecs[item_id].T\n",
    "\n",
    "# Calculate the similarity score between Mr Carter and other artists\n",
    "# and select the top 10 most similar.\n",
    "scores = item_vecs.dot(item_vec).toarray().reshape(1,-1)[0]\n",
    "top_10 = np.argsort(scores)[::-1][:10]\n",
    "\n",
    "artists = []\n",
    "artist_scores = []\n",
    "\n",
    "# Get and print the actual artists names and scores\n",
    "for idx in top_10:\n",
    "    artists.append(item_lookup.artist.loc[item_lookup.artist_id == str(idx)].iloc[0])\n",
    "    artist_scores.append(scores[idx])\n",
    "\n",
    "similar = pd.DataFrame({'artist': artists, 'score': artist_scores})\n",
    "\n",
    "print(similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say we want to recommend artists for user with ID 2023\n",
    "user_id = 2023\n",
    "\n",
    "#------------------------------\n",
    "# GET ITEMS CONSUMED BY USER\n",
    "#------------------------------\n",
    "\n",
    "# Let's print out what the user has listened to\n",
    "consumed_idx = data_sparse[user_id,:].nonzero()[1].astype(str)\n",
    "consumed_items = item_lookup.loc[item_lookup.artist_id.isin(consumed_idx)]\n",
    "print consumed_items\n",
    "\n",
    "\n",
    "#------------------------------\n",
    "# CREATE USER RECOMMENDATIONS\n",
    "#------------------------------\n",
    "\n",
    "def recommend(user_id, data_sparse, user_vecs, item_vecs, item_lookup, num_items=10):\n",
    "    \"\"\"Recommend items for a given user given a trained model\n",
    "    \n",
    "    Args:\n",
    "        user_id (int): The id of the user we want to create recommendations for.\n",
    "        \n",
    "        data_sparse (csr_matrix): Our original training data.\n",
    "        \n",
    "        user_vecs (csr_matrix): The trained user x features vectors\n",
    "        \n",
    "        item_vecs (csr_matrix): The trained item x features vectors\n",
    "        \n",
    "        item_lookup (pandas.DataFrame): Used to map artist ids to artist names\n",
    "        \n",
    "        num_items (int): How many recommendations we want to return:\n",
    "        \n",
    "    Returns:\n",
    "        recommendations (pandas.DataFrame): DataFrame with num_items artist names and scores\n",
    "    \n",
    "    \"\"\"\n",
    "  \n",
    "    # Get all interactions by the user\n",
    "    user_interactions = data_sparse[user_id,:].toarray()\n",
    "\n",
    "    # We don't want to recommend items the user has consumed. So let's\n",
    "    # set them all to 0 and the unknowns to 1.\n",
    "    user_interactions = user_interactions.reshape(-1) + 1 #Reshape to turn into 1D array\n",
    "    user_interactions[user_interactions > 1] = 0\n",
    "\n",
    "    # This is where we calculate the recommendation by taking the \n",
    "    # dot-product of the user vectors with the item vectors.\n",
    "    rec_vector = user_vecs[user_id,:].dot(item_vecs.T).toarray()\n",
    "\n",
    "    # Let's scale our scores between 0 and 1 to make it all easier to interpret.\n",
    "    min_max = MinMaxScaler()\n",
    "    rec_vector_scaled = min_max.fit_transform(rec_vector.reshape(-1,1))[:,0]\n",
    "    recommend_vector = user_interactions*rec_vector_scaled\n",
    "   \n",
    "    # Get all the artist indices in order of recommendations (descending) and\n",
    "    # select only the top \"num_items\" items. \n",
    "    item_idx = np.argsort(recommend_vector)[::-1][:num_items]\n",
    "\n",
    "    artists = []\n",
    "    scores = []\n",
    "\n",
    "    # Loop through our recommended artist indicies and look up the actial artist name\n",
    "    for idx in item_idx:\n",
    "        artists.append(item_lookup.artist.loc[item_lookup.artist_id == str(idx)].iloc[0])\n",
    "        scores.append(recommend_vector[idx])\n",
    "\n",
    "    # Create a new dataframe with recommended artist names and scores\n",
    "    recommendations = pd.DataFrame({'artist': artists, 'score': scores})\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Let's generate and print our recommendations\n",
    "recommendations = recommend(user_id, data_sparse, user_vecs, item_vecs, item_lookup)\n",
    "print(recommendations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
